# -*- coding: utf-8 -*-
"""DAY@2TASK

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17Es8nCshlHYdyyk1xk9hUnTJKQCEVozo
"""

!pip install opencv-python matplotlib
import cv2
import matplotlib.pyplot as plt







from google.colab import files
uploaded = files.upload()
img = cv2.imread(list(uploaded.keys())[0]) #load image
img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)

plt.imshow(img)
plt.axis('off')
plt.show()

cropped = img[100:400, 200:500]

rotated = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)

plt.figure(figsize=(10,5))
plt.subplot(1,2,1); plt.imshow(img); plt.title("original")
plt.subplot(1,2,2);plt.imshow(rotated);plt.title("Rotated")
plt.show()

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
edges = cv2.Canny(gray, 100, 200) # Play with thresholds!

plt.imshow(edges, cmap='gray')
plt.title("Edges Detected!")
plt.show()



import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

# Parameters
vocab_size =1000   # Number of unique words in your vocabulary
embedding_dim = 64 # Size of word vector representations
max_length = 100   # Max length of input sequences

# Define model
model = Sequential([
    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),
    LSTM(64),
    Dense(1, activation='sigmoid')  # Use 'softmax' if you have multiple classes
])

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Model summary
model.summary()